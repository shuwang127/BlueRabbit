{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/shuwang127/kcaH/blob/master/run.ipynb",
      "authorship_tag": "ABX9TyMIAc8TYh2VwLp1YjTdg6Fd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuwang127/BlueRabbit/blob/master/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gG9ydeFW4T0",
        "colab_type": "text"
      },
      "source": [
        "## Preliminary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fvXWVieXQWq",
        "colab_type": "text"
      },
      "source": [
        "Import dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcOj9hy9XI0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import string\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_k9iGobXKvf",
        "colab_type": "text"
      },
      "source": [
        "Global path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U4w0UsJXPcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# global path.\n",
        "rootPath = '/content/drive/My Drive/Colab Notebooks/'\n",
        "dataPath = rootPath + '/data/'\n",
        "tempPath = rootPath + '/temp/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH1IZVXOXXOk",
        "colab_type": "text"
      },
      "source": [
        "## Main function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StOUba9JXaV4",
        "colab_type": "text"
      },
      "source": [
        "main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbkSFi-mXcq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    print('=================================== BlueRabbit Team ===================================')\n",
        "    print('[Info] Process the news documents ...')\n",
        "    locKeywords, raceKeywords, contents = ReadData()\n",
        "    print('[Info] Information from the title and contents ...')\n",
        "    print(contents)\n",
        "    print('[Info] Information from the county and state ...')\n",
        "    print(locKeywords)\n",
        "    print('[Info] Information from the race ...')\n",
        "    print(raceKeywords)\n",
        "    print('---------------------------------------------------------------------------------------')\n",
        "    dsetNew, labels, county = Process()\n",
        "    prior, likelihood = TrainNaiveBayes(dsetNew, labels)\n",
        "    print('[Para] Model parameters:')\n",
        "    print(prior)\n",
        "    print(likelihood)\n",
        "    probs = TestNaiveBayes(prior, likelihood, dsetNew)\n",
        "    print('[Info] Get the first-order probabilities from evaluation.')\n",
        "    print('---------------------------------------------------------------------------------------')\n",
        "    print('[Info] Combining the information from news.')\n",
        "    probs = ProbsAdjust(probs, county, dsetNew, locKeywords, raceKeywords, contents)\n",
        "    print('[Info] Get the second-oder probabilities from evaluation.')\n",
        "    Write2File(probs)\n",
        "    print('[Info] Analysis done!')\n",
        "    print('---------------------------------------------------------------------------------------')\n",
        "    filename = dataPath + 'Roe-Sepowitzd et al (2019).txt'\n",
        "    print('[Info] Input a new text file: ' + filename + '.')\n",
        "    keywords = ReadFile(filename)\n",
        "    print('[Info] Get the keywords (w. weights) from the text:')\n",
        "    print(keywords)\n",
        "    print('=================================== BlueRabbit Team ===================================')\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13mx84HNXneb",
        "colab_type": "text"
      },
      "source": [
        "## Bayes Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX-ox1pKXtQl",
        "colab_type": "text"
      },
      "source": [
        "Training model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3uxhDK5XvUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the naive bayes model.\n",
        "def TrainNaiveBayes(features, labels):\n",
        "    '''\n",
        "    train the naive bayes model.\n",
        "    :param features: training set features\n",
        "    :return: model parameters - prior, likelihood\n",
        "    '''\n",
        "    # define the log prior.\n",
        "    def GetLogPrior(labelTrain):\n",
        "        # count the number.\n",
        "        nTotal = len(labelTrain)\n",
        "        nPos = list(labelTrain).count(1)\n",
        "        nNag = list(labelTrain).count(0)\n",
        "        # calculate the logprior.\n",
        "        priorPos = math.log(nPos / nTotal)\n",
        "        priorNag = math.log(nNag / nTotal)\n",
        "        prior = [priorNag, priorPos]\n",
        "        return prior\n",
        "\n",
        "    # define loglikelihood.\n",
        "    def GetLogLikelihood(features, labelTrain):\n",
        "        # get V and D.\n",
        "        V = len(features[0])\n",
        "        D = len(features)\n",
        "        cls = 2\n",
        "        # initilaze likelihood matrix.\n",
        "        likelihood = np.zeros((cls, V))\n",
        "        for ind in range(D):\n",
        "            for i in range(V):\n",
        "                likelihood[labelTrain[ind]][i] += features[ind][i]\n",
        "        # Laplace smoothing.\n",
        "        denom = np.zeros((cls, 1))\n",
        "        for lb in range(cls):\n",
        "            denom[lb] = sum(likelihood[lb]) + V\n",
        "            for i in range(V):\n",
        "                likelihood[lb][i] += 1\n",
        "                likelihood[lb][i] /= denom[lb]\n",
        "                likelihood[lb][i] = math.log(likelihood[lb][i])\n",
        "        return likelihood\n",
        "\n",
        "    # get the log prior.\n",
        "    prior = GetLogPrior(labels)\n",
        "    # get the log likelihood\n",
        "    likelihood = GetLogLikelihood(features, labels)\n",
        "    return prior, likelihood"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m38i8FO_Xx52",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJxcqSLXzB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test and evaluate the performance.\n",
        "def TestNaiveBayes(prior, likelihood, featTest):\n",
        "    # get predictions for testing samples with model parameters.\n",
        "    def GetPredictions(prior, likelihood, featTest):\n",
        "        # get V and D.\n",
        "        V = len(featTest[0])\n",
        "        D = len(featTest)\n",
        "        cls = 2\n",
        "        T = 0.015\n",
        "        # get pred(D, cls) matrix and predictions(D, 1).\n",
        "        pred = np.zeros((D, cls))\n",
        "        predictions = np.zeros((D, 1))\n",
        "        probs = np.zeros((D, 1))\n",
        "        for ind in range(D):\n",
        "            for lb in range(cls):\n",
        "                pred[ind][lb] += prior[lb]\n",
        "                for i in range(V):\n",
        "                    pred[ind][lb] += likelihood[lb][i] * featTest[ind][i]\n",
        "            predictions[ind] = list(pred[ind]).index(max(pred[ind]))\n",
        "            p0 = pred[ind][0] / (pred[ind][0] + pred[ind][1])\n",
        "            p1 = pred[ind][1] / (pred[ind][0] + pred[ind][1])\n",
        "            probs[ind] = math.exp(p1/T) / (math.exp(p0/T) + math.exp(p1/T))\n",
        "        return predictions, probs\n",
        "\n",
        "    # get predictions for testing samples.\n",
        "    predictions, probs = GetPredictions(prior, likelihood, featTest)\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzxKMe1lX0Mv",
        "colab_type": "text"
      },
      "source": [
        "## Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaLedPptYB8F",
        "colab_type": "text"
      },
      "source": [
        "News Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7SVJpOWYE9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadData():\n",
        "    # read csv file.\n",
        "    filePath = dataPath + '/NewsData.csv'\n",
        "    dset = pd.read_csv(filePath)\n",
        "    # weights\n",
        "    numCase = [int(item) if is_number(item) else 1 for item in dset['case']]\n",
        "    numCriminals = [int(item) if is_number(item) else 1 for item in dset['#Criminals']]\n",
        "    numClass = [2 if item == 'havecase' else 1 for item in dset['Category']]\n",
        "    weights = [numCase[i] * numCriminals[i] * numClass[i] for i in range(len(numCase))]\n",
        "    # get locations.\n",
        "    locKeywords = dict()\n",
        "    for i in range(len(weights)):\n",
        "        loc = dset['traffic/aresst_location'][i]\n",
        "        if loc not in locKeywords.keys():\n",
        "            locKeywords[loc] = 0\n",
        "        locKeywords[loc] += weights[i]\n",
        "    locKeywords = SortDict(locKeywords)\n",
        "    # get race.\n",
        "    raceKeywords = dict()\n",
        "    for i in range(len(weights)):\n",
        "        race = dset['c_race'][i]\n",
        "        if race not in raceKeywords.keys():\n",
        "            raceKeywords[race] = 0\n",
        "        raceKeywords[race] += weights[i]\n",
        "    raceKeywords = SortDict(raceKeywords)\n",
        "    # get content and title.\n",
        "    counties = GetCounty()\n",
        "    contents = dict()\n",
        "    for i in range(len(weights)):\n",
        "        text = dset['title'][i] + ' ' + dset['Content'][i]\n",
        "        text = string.capwords(text)\n",
        "        for county in counties:\n",
        "            num = text.count(county)\n",
        "            if num != 0:\n",
        "                if county not in contents.keys():\n",
        "                    contents[county] = 0\n",
        "                contents[county] += num * weights[i]\n",
        "    contents = SortDict(contents)\n",
        "    # return\n",
        "    return locKeywords, raceKeywords, contents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPS_UzoEZI1F",
        "colab_type": "text"
      },
      "source": [
        "Hotel information processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpOKIDwEYX5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Process():\n",
        "    filename = dataPath + '/datahub.csv'\n",
        "    dset = pd.read_csv(filename)\n",
        "    dsetNew = pd.DataFrame()\n",
        "    # price_room_per_night\n",
        "    dsetNew['price_room_per_night'] = [int(item[1:]) for item in dset['price_room_per_night']]\n",
        "    # star\n",
        "    dsetNew['Star'] = dset['Star']\n",
        "    # city_has_criminal_recorded_courtcase\n",
        "    dsetNew['city_has_criminal_recorded_courtcase'] = dset['city_has_criminal_recorded_courtcase']\n",
        "    # hotspot_Paloris\n",
        "    dsetNew['hotspot_Paloris'] = dset['hotspot_Paloris']\n",
        "    # strip_club_40min\n",
        "    dsetNew['strip_club_40min'] = dset['strip_club_40min']\n",
        "    # # massage_parlor_nearby\n",
        "    dsetNew['# massage_parlor_nearby'] = dset['# massage_parlor_nearby']\n",
        "    # identified_online_ads\n",
        "    dsetNew['identified_online_ads'] = dset['identified_online_ads']\n",
        "    # recent_has_sport_event\n",
        "    dsetNew['recent_has_sport_event'] = dset['recent_has_sport_event']\n",
        "    # race_white_more_than_60%\n",
        "    dsetNew['race_white_more_than_60%'] = dset['race_white_more_than_60%']\n",
        "    # male_avg_Earning\n",
        "    dsetNew['male_avg_Earning'] = [int(item[1:-4]) * 1000 + int(item[-3:]) for item in dset['male_avg_Earning']]\n",
        "    # Single_Rate\n",
        "    dsetNew['Single_Rate'] = [float(item[0:-1]) for item in dset['Single_Rate']]\n",
        "    # white_male\n",
        "    dsetNew['white_male'] = dset['white_male']\n",
        "    # white_average\n",
        "    dsetNew['white_average'] = [float(item[0:-1]) for item in dset['white_average']]\n",
        "    # male_rate\n",
        "    dsetNew['male_rate'] = [float(item[0:-1]) for item in dset['male_rate']]\n",
        "    # marriage_rate\n",
        "    dsetNew['marriage_rate'] = [float(item[0:-1]) for item in dset['marriage_rate']]\n",
        "    # Ave_Earning\n",
        "    dsetNew['Ave_Earning'] = [int(item[1:-4]) * 1000 + int(item[-3:]) for item in dset['Ave_Earning']]\n",
        "    dsetNew = dsetNew.values.tolist()\n",
        "    # list.\n",
        "    filename = dataPath + '/labels.csv'\n",
        "    labels = pd.read_csv(filename)\n",
        "    labels = labels.values.tolist()\n",
        "    labels = [item[0] for item in labels]\n",
        "    return dsetNew, labels, dset['County_seat'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPcBnFlKKhQ_",
        "colab_type": "text"
      },
      "source": [
        "Read File."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn991px7Knv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadFile(filename):\n",
        "    locKeywords, raceKeywords, contents = ReadData()\n",
        "    # get keyword list\n",
        "    keywordList = []\n",
        "    keywordList.extend([item for item in locKeywords if locKeywords[item] >= 8])\n",
        "    keywordList.extend([item for item in raceKeywords if raceKeywords[item] >= 10])\n",
        "    keywordList.extend([item for item in contents if contents[item] >= 30])\n",
        "    keywordListExt = ['customer', 'white', 'male', 'business model', 'post', 'online', 'advertise', 'transport to',\\\n",
        "                      'hotel', 'motel', 'apartment, book', 'telephone', 'phone number', 'eastern district of Virginia', \\\n",
        "                      'Maryland', 'Washington DC', 'strip club', 'bar', 'massage parlor', 'hotspot', 'commercial sex act',\\\n",
        "                      'sex', 'trafficking', 'high income', 'earnings']\n",
        "    keywordList.extend([string.capwords(item) for item in keywordListExt])\n",
        "    keywordList = list(set(keywordList))\n",
        "    # read file.\n",
        "    fp = open(filename, encoding='utf-8')\n",
        "    text = fp.read()\n",
        "    text = string.capwords(text)\n",
        "    # statistic.\n",
        "    keywords = dict()\n",
        "    for item in keywordList:\n",
        "        if (type(item) == str):\n",
        "            num = text.count(item)\n",
        "            if num != 0:\n",
        "                keywords[item] = num\n",
        "    keywords = SortDict(keywords)\n",
        "    # return\n",
        "    return keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9tnp953YY9B",
        "colab_type": "text"
      },
      "source": [
        "## Probability Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Wx82pdYiRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ProbsAdjust(probs, county, dset, locKeywords, raceKeywords, contents):\n",
        "    # adjust information from locKeywords\n",
        "    for i in range(len(probs)):\n",
        "        # locKeywords.\n",
        "        p = 0\n",
        "        if (county[i] in locKeywords):\n",
        "            p = locKeywords[county[i]] / (sum(locKeywords.values()))\n",
        "        t = (math.exp(p) - 1) / (math.exp(1) - 1)\n",
        "        probs[i] = (1 - t) * probs[i] + t\n",
        "    # adjust information from contents.\n",
        "    for i in range(len(probs)):\n",
        "        # contents\n",
        "        p = 0\n",
        "        if (county[i] in contents):\n",
        "            p = contents[county[i]] / (sum(contents.values()))\n",
        "        t = (math.exp(p) - 1) / (math.exp(1) - 1)\n",
        "        probs[i] = (1 - t) * probs[i] + t\n",
        "    # race\n",
        "    for i in range(len(probs)):\n",
        "        p = raceKeywords['White'] / (sum(raceKeywords.values())) * dset[i][-4] / 100\n",
        "        t = (math.exp(p) - 1) / (math.exp(1) - 1)\n",
        "        probs[i] = (1 - t) * probs[i] + t\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htdaAW3eYpCg",
        "colab_type": "text"
      },
      "source": [
        "## Other funtions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWgjyGhzYqHR",
        "colab_type": "text"
      },
      "source": [
        "Get VA county names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3lTYojoYyYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetCounty():\n",
        "    # get counties.\n",
        "    df = pd.read_csv(dataPath + '/laucnty16.csv')\n",
        "    counties = [item.split(',')[0] for item in df['County Name/State Abbreviation'] if ', VA' in item]\n",
        "    counties = [item[:-7] if ' County' in item else item for item in counties]\n",
        "    counties = [item[:-5] if ' city' in item else item for item in counties]\n",
        "    # add.\n",
        "    countiesExtend = ['Springfield', 'Sterling', 'Alexandria', 'Woodbridge', 'Centreville', 'Chantilly'\\\n",
        "                      'Fairfax', 'Herdon', 'Tyson', 'Ashburn', 'Manassas', 'Vienna']\n",
        "    counties.extend(countiesExtend)\n",
        "    # delete.\n",
        "    counties.remove('Washington')\n",
        "    # unorder.\n",
        "    counties = list(set(counties))\n",
        "    # print(counties)\n",
        "    return counties"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weF-sS3-YzhB",
        "colab_type": "text"
      },
      "source": [
        "judge number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUfglmJ4YkWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        if math.isnan(float(s)):\n",
        "            return False\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-eNGlnY4eQ",
        "colab_type": "text"
      },
      "source": [
        "Sort dictionary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o4Y7lp5Y_Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SortDict(d):\n",
        "    dNew = dict()\n",
        "    while (len(d)):\n",
        "        item = max(d, key=d.get)\n",
        "        dNew[item] = d[item]\n",
        "        d.pop(item)\n",
        "    return dNew"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NGQSL86ZAKw",
        "colab_type": "text"
      },
      "source": [
        "Write to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u4vm_92W0X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Write2File(probs):\n",
        "    # read csv file.\n",
        "    filePath = dataPath + '/datahub.csv'\n",
        "    dset = pd.read_csv(filePath)\n",
        "    dset['risk'] = probs\n",
        "    dset.to_csv(dataPath + '/risk.csv')\n",
        "    print('[Info] Results have been saved in ' + dataPath + '/risk.csv')\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HES0_9llaHkq",
        "colab_type": "text"
      },
      "source": [
        "## Entrance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rxkYFKyaJ0s",
        "colab_type": "code",
        "outputId": "c354cb4e-5773-414f-b2e7-592029717e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=================================== BlueRabbit Team ===================================\n",
            "[Info] Process the news documents ...\n",
            "[Info] Information from the title and contents ...\n",
            "{'Springfield': 441, 'Fairfax': 307, 'Virginia Beach': 248, 'Manassas': 204, 'Arlington': 192, 'Alexandria': 175, 'York': 110, 'Craig': 96, 'Prince William': 90, 'Woodbridge': 90, 'Warren': 56, 'Fauquier': 55, 'Norfolk': 48, 'Chesapeake': 48, 'Frederick': 37, 'Fredericksburg': 37, 'Falls Church': 34, 'Loudoun': 33, 'Lee': 33, 'Hampton': 22, 'Stafford': 20, 'Greene': 16, 'Staunton': 8, 'Spotsylvania': 8, 'Suffolk': 6, 'Middlesex': 6}\n",
            "[Info] Information from the county and state ...\n",
            "{'Bellevue': 108, 'Alexandria': 104, 'Springfield': 97, 'Virginia Beach': 76, 'Arlington': 45, 'Tulsa': 36, 'Woodbridge': 33, 'Fairfax': 30, 'Falls Church': 14, 'Manassas': 8, 'Central and Florida St.': 6, 'Cambridge': 6, 'Southwest': 4, 'Stafford': 4, 'DC': 1, nan: 1}\n",
            "[Info] Information from the race ...\n",
            "{'Mix': 153, nan: 136, 'African-American': 120, 'White': 96, 'Chinese': 34, 'Asian': 20, 'whtie': 14}\n",
            "---------------------------------------------------------------------------------------\n",
            "[Para] Model parameters:\n",
            "[-0.04652001563489282, -3.0910424533583156]\n",
            "[[ -7.53818322 -11.01853029 -12.13435471 -11.84667264 -11.84667264\n",
            "  -11.86242099 -12.01657167 -16.00555572 -13.11518396  -0.73917869\n",
            "   -7.98827789  -2.1326501   -7.66849448  -7.96826459  -7.91328878\n",
            "   -0.91162976]\n",
            " [ -7.250962   -10.53936389 -11.16797255 -11.16797255 -11.16797255\n",
            "  -11.16797255 -11.16797255 -12.55426691 -11.86111973  -0.71110288\n",
            "   -7.5012109   -2.48468627  -7.32171548  -7.57031788  -7.57409082\n",
            "   -0.86159821]]\n",
            "[Info] Get the first-order probabilities from evaluation.\n",
            "---------------------------------------------------------------------------------------\n",
            "[Info] Combining the information from news.\n",
            "[Info] Get the second-oder probabilities from evaluation.\n",
            "[Info] Results have been saved in /content/drive/My Drive/Colab Notebooks//data//risk.csv\n",
            "[Info] Analysis done!\n",
            "---------------------------------------------------------------------------------------\n",
            "[Info] Input a new text file: /content/drive/My Drive/Colab Notebooks//data/Roe-Sepowitzd et al (2019).txt.\n",
            "[Info] Get the keywords (w. weights) from the text:\n",
            "{'Sex': 100, 'Male': 15, 'Online': 11, 'Bar': 3, 'Customer': 2, 'Massage Parlor': 2, 'Telephone': 1, 'White': 1, 'Advertise': 1, 'Strip Club': 1}\n",
            "=================================== BlueRabbit Team ===================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}